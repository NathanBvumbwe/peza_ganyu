{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI+FquHvZDJFUgySKRIvLB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NathanBvumbwe/peza_ganyu/blob/main/model2_recomender_training_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzZ1BfDjE3wu",
        "outputId": "0f68e721-0fe1-4068-8ee3-829b418bce65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('data_job_categories.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm0T-eYmMQWr",
        "outputId": "551c4eb0-b8cb-49b7-8858-31651044a190"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     title         category\n",
            "0       Finance & Administration Assistant          Finance\n",
            "1          Volunteer Liaison (2 Positions)  Human Resources\n",
            "2            Finance and Program Assistant          Finance\n",
            "3             Account Relationship Officer          Finance\n",
            "4  Media Monitoring and Evaluation Officer        Marketing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Split the dataset\n",
        "train_df, test_df = train_test_split(df, test_size=0.2)\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the job titles\n",
        "def tokenize(text):\n",
        "    return tokenizer(text, padding='max_length', truncation=True, return_tensors='pt')\n",
        "\n",
        "train_encodings = tokenize(train_df['title'].tolist())\n",
        "test_encodings = tokenize(test_df['title'].tolist())"
      ],
      "metadata": {
        "id": "NYh-5gJaMQTL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class JobDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Assuming 'category' is your label\n",
        "train_dataset = JobDataset(train_encodings, train_df['category'].tolist())\n",
        "test_dataset = JobDataset(test_encodings, test_df['category'].tolist())"
      ],
      "metadata": {
        "id": "cU2xgRaYMQQ0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1SXPxJTPKJX",
        "outputId": "27e9a55c-688f-4e78-b147-1439a8acfd3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['category'].unique()))\n",
        "\n",
        "# Set up training arguments without evaluation strategy\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10  # Log every 10 steps\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "mRlFhHqsMQN8",
        "outputId": "e922cf45-d4a5-4032-bd95-afce6fefb30e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnathanbvumbwe21\u001b[0m (\u001b[33mnathanbvumbwe21-mzuzu-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250710_122633-a62dkieh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nathanbvumbwe21-mzuzu-university/huggingface/runs/a62dkieh' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/nathanbvumbwe21-mzuzu-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nathanbvumbwe21-mzuzu-university/huggingface' target=\"_blank\">https://wandb.ai/nathanbvumbwe21-mzuzu-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nathanbvumbwe21-mzuzu-university/huggingface/runs/a62dkieh' target=\"_blank\">https://wandb.ai/nathanbvumbwe21-mzuzu-university/huggingface/runs/a62dkieh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "new(): invalid data type 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-2616797029.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2204\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2206\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2207\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2500\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2502\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2503\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5299\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5300\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5301\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5302\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-14-3006888925.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('data_job_categories.csv')\n",
        "print(df.head())  # Check the first few rows for confirmation\n",
        "\n",
        "# Load BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['category'].unique()))\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10  # Log every 10 steps\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "7ZpCMTPVMQLk",
        "outputId": "76ffeadd-a3ef-4982-ac79-3ef0bb839828"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     title         category\n",
            "0       Finance & Administration Assistant          Finance\n",
            "1          Volunteer Liaison (2 Positions)  Human Resources\n",
            "2            Finance and Program Assistant          Finance\n",
            "3             Account Relationship Officer          Finance\n",
            "4  Media Monitoring and Evaluation Officer        Marketing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "new(): invalid data type 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-17-781154686.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2204\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2206\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2207\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2500\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2502\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2503\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5299\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5300\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5301\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5302\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-14-3006888925.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Reset Python state\n",
        "%reset -f\n",
        "\n",
        "# Step 2: Force reinstall latest transformers\n",
        "!pip install -U transformers\n",
        "\n",
        "# Step 3: Re-import after clean install\n",
        "from transformers import TrainingArguments\n",
        "print(TrainingArguments.__module__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGj5elacMQI9",
        "outputId": "89cca2ff-1344-4f44-cf80-a7a94f3d1459"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "transformers.training_args\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"./test\",\n",
        "    evaluation_strategy=\"steps\"\n",
        ")\n",
        "print(\"Success!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "-bZnS83DMQGG",
        "outputId": "29c6b0e7-9a70-423a-a7d1-60a8e9fecd80"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-1153645290.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m args = TrainingArguments(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mevaluation_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Success!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQKbKgUNMP73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sj3kxNnZW0WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAIYAMBILASO APA MAN"
      ],
      "metadata": {
        "id": "KFSeHzrRW1JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the dataset\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data_job_categories.csv')\n",
        "print(df.head())  # Check the first few rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL-JhIJ_W0Sw",
        "outputId": "4155a065-3969-4bad-a75b-666a549dada7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     title         category\n",
            "0       Finance & Administration Assistant          Finance\n",
            "1          Volunteer Liaison (2 Positions)  Human Resources\n",
            "2            Finance and Program Assistant          Finance\n",
            "3             Account Relationship Officer          Finance\n",
            "4  Media Monitoring and Evaluation Officer        Marketing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3f22gpjNW0Pq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Encode the labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_df['category'].tolist())\n",
        "test_labels = label_encoder.transform(test_df['category'].tolist())"
      ],
      "metadata": {
        "id": "WZqKdsHrW0My"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load BERT tokenizer\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "V1TEfzOkW0Ka"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Tokenize the job titles\n",
        "def tokenize(text):\n",
        "    return tokenizer(text, padding='max_length', truncation=True, return_tensors='pt', max_length=128)\n",
        "\n",
        "train_encodings = tokenize(train_df['title'].tolist())\n",
        "test_encodings = tokenize(test_df['title'].tolist())"
      ],
      "metadata": {
        "id": "yWyfgRd5W0Hz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Create a Dataset class\n",
        "import torch\n",
        "\n",
        "class JobDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "qsZcjEI7W0Fb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Create datasets\n",
        "train_dataset = JobDataset(train_encodings, train_labels)\n",
        "test_dataset = JobDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "4I2tbL0PW0CV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Load BERT model\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRf9EgGlWz_9",
        "outputId": "4359063b-af48-40ce-bb0e-d20fcbd30a03"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Set up training arguments\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10\n",
        ")"
      ],
      "metadata": {
        "id": "7Uwv8P80Wz83"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Create Trainer instance\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "c7ieh-PXWz6Q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "id": "furIWmmrWz3p",
        "outputId": "3453c16f-d16c-4cbe-e97a-2f632be1101c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 47:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.911400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.878600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.839200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.814000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.786900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.717900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.704400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.686900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.648300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.627300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>2.614700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.604600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>2.538200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.600800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.443000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>2.446400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.408500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.399500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>2.354800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.255500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>2.081200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>2.023200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>2.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>2.008700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.705300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.596400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.645500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=270, training_loss=2.422454018063015, metrics={'train_runtime': 2883.2149, 'train_samples_per_second': 0.745, 'train_steps_per_second': 0.094, 'total_flos': 141307128419328.0, 'train_loss': 2.422454018063015, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Evaluate the model (optional)\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "0iYH4_b6Wz1C",
        "outputId": "b3d9b534-ac0c-48e5-e7e6-96060c848c09"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23/23 01:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 1.5280487537384033,\n",
              " 'eval_runtime': 68.9286,\n",
              " 'eval_samples_per_second': 2.597,\n",
              " 'eval_steps_per_second': 0.334,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPFnqOMNWzyb",
        "outputId": "4dc117b7-6a76-4934-a139-7db0c6d1c437"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Get predictions\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Step 2: Calculate metrics\n",
        "accuracy = accuracy_score(test_labels, preds)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, preds, average='weighted')\n",
        "\n",
        "# Step 3: Print metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "46772S9hWzvk",
        "outputId": "cedbe38a-5fc2-4a19-8d0e-6d06af00b5e7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6257\n",
            "Precision: 0.5823\n",
            "Recall: 0.6257\n",
            "F1 Score: 0.5660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Evaluate the model (optional)\n",
        "trainer.evaluate()\n",
        "\n",
        "# Additional evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "# Get predictions\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(test_labels, preds)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, preds, average='weighted')\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "MdJwdrCnWztP",
        "outputId": "35ca5980-233d-4caa-f598-bb9bea90fd8e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6257\n",
            "Precision: 0.5823\n",
            "Recall: 0.6257\n",
            "F1 Score: 0.5660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# Step 1: Save the model and tokenizer\n",
        "model.save_pretrained('./saved_model')\n",
        "tokenizer.save_pretrained('./saved_model')\n",
        "\n",
        "# Step 2: Zip the saved model directory\n",
        "shutil.make_archive('saved_model', 'zip', './saved_model')\n",
        "\n",
        "# Step 3: List the files for confirmation\n",
        "os.listdir('./saved_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfc5OPcGWzqV",
        "outputId": "138482b3-df03-4b22-b451-dbd30bdb1f11"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tokenizer_config.json',\n",
              " 'vocab.txt',\n",
              " 'config.json',\n",
              " 'special_tokens_map.json',\n",
              " 'model.safetensors']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('saved_model.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ouR2dF_zWzn-",
        "outputId": "43db28fd-b599-4f9c-bc98-3070c250f846"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5000f308-9a69-4051-aeb8-aed7ee1c5fe4\", \"saved_model.zip\", 405733027)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k7N7s_9bmrQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RE-TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "lsOnEsJJou0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Set up training arguments\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,  # Increased number of epochs\n",
        "    per_device_train_batch_size=16,  # Increased batch size\n",
        "    per_device_eval_batch_size=16,    # Increased eval batch size\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10\n",
        ")"
      ],
      "metadata": {
        "id": "lSJYLWz4mrNk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Create Trainer instance\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "J0myIvM2mrLq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "u5_0tBl5mrI_",
        "outputId": "a05cbf4a-39e1-4bcc-9341-a26c46c247f5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [225/225 1:14:00, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.423600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.318900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.428300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.357900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.354400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.394000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.238400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.203300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.140300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.169700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.093500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.099700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.837600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.959800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.763300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.751900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.852700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.732800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.661900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.556800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.511000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.544000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=225, training_loss=1.0062047290802, metrics={'train_runtime': 4465.7251, 'train_samples_per_second': 0.802, 'train_steps_per_second': 0.05, 'total_flos': 235511880698880.0, 'train_loss': 1.0062047290802, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "0vGjJFlGmrE8",
        "outputId": "d6d56d32-91b4-47cb-fe7e-fcc0e657b645"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12/12 01:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7393033504486084, 'eval_runtime': 66.8227, 'eval_samples_per_second': 2.679, 'eval_steps_per_second': 0.18, 'epoch': 5.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Get predictions\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Assuming test_labels contains your true labels\n",
        "accuracy = accuracy_score(test_labels, preds)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, preds, average='weighted')\n",
        "\n",
        "# Print detailed metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "YMD1Bh4DExp3",
        "outputId": "dce3c218-13bb-4e74-e32f-5b1c3e9ea9e1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8101\n",
            "Precision: 0.8313\n",
            "Recall: 0.8101\n",
            "F1 Score: 0.7995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Ch1yNAExoH",
        "outputId": "85c34083-2b0e-4e44-fdf8-5d26c1e7f0c1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the metrics from the evaluation\n",
        "metrics = {\n",
        "    'Accuracy': accuracy,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1 Score': f1,\n",
        "}\n",
        "\n",
        "# Create bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(metrics.keys(), metrics.values(), color=['blue', 'orange', 'green', 'red'])\n",
        "plt.ylim(0, 1)  # Setting the y-axis limits\n",
        "plt.title('Model Evaluation Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metrics')\n",
        "plt.grid(axis='y')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "z059VT5rExlf",
        "outputId": "a3505649-a756-4d78-baa5-f222244bea4f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained('./saved_model')\n",
        "tokenizer.save_pretrained('./saved_model')\n",
        "\n",
        "# Zip the saved model directory\n",
        "shutil.make_archive('saved_model', 'zip', './saved_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "kluPdtEzExei",
        "outputId": "43251956-cf3d-41f0-f952-d156083a82e5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/saved_model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the zipped file\n",
        "files.download('saved_model.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lQLU8WY3ExcD",
        "outputId": "e1cdc8ac-2011-499f-e083-7111a15470c6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db6e90e2-db2d-4dea-9be0-1fb394a53546\", \"saved_model.zip\", 405731277)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tl9QiRzhMIHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HsDjFP62MIDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKCDGIyeMIA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UvwRIFSWMH-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yh5mOiV-MH7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "diNxkQyWMH5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7xVcn4hMH2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}